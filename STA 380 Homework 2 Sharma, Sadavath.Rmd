---
title: "Assignment 2"
author: "Sadavath Sharma"
date: "August 18, 2015"
output: html_document
---

###Question1: 

#### Departure Delays are worst on the Mondays of the month March. The second worst delays are on the Sundays of June.The months of September, October and November are least affected by Departure Delays.

#### Departure Delays are mostly between 1600 and 2100 hours. The most affected weekdays are Thursdays, Fridays and Sundays

#### Mondays in the month of March and Fridays in the month of April are the worst effected by the delays in Arrival

#### Arrival Delays are mostly between 1600 and 2200 hours, a lot similar to the Delay Delays. 


###Question2: Author Attribution

#### We Import the libraries. The 'tm' library will used to the text mining commands, eg: tokenization of training and test corpus and readplain command. The 'randomForest' library is used because we run the Random Forest model as one of our methods. The 'e1071' library is used because we are using the Naive Bayes model model. 
```{r}
library(tm)
library(randomForest)
library(e1071)
library(rpart)
library(ggplot2)
library(caret)
```

#### We create a Reader function which reads each line through the readPlain function. This function reads in a text document without knowledge about its internal structure and possible available metadata.
```{r}
readerPlain = function(fname){
  readPlain(elem=list(content=readLines(fname)), id=fname, language='en') }
```

#### Now, we create the Training Corpus. The sys.glob function here is a function to do wildcard expansion on file paths.  
```{r}
author_dirs = Sys.glob('./ReutersC50/C50train/*')
file_list = NULL
train_labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first=23)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  train_labels = append(train_labels, rep(author_name, length(files_to_add)))
}
```

#### We perform Named conversion & cleanup of the file. The lapply function here returns a list of the same length as file_list, each element of which is the result of applying readerPlain to the corresponding element of file_list 
```{r}
all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
```

#### In the next step, we initialize Training Corpus 
```{r}
train_corpus = Corpus(VectorSource(all_docs))
names(train_corpus) = file_list
```

####Tokenization of training Corpus: Now, in order to tokenize the training corpus, we follow the followin steps: First we convert the content of train_corpus to lowercase. Then, we remove numbers and punctuation. Next, we strip the white spaces
```{r}
train_corpus = tm_map(train_corpus, content_transformer(tolower)) 
train_corpus = tm_map(train_corpus, content_transformer(removeNumbers)) 
train_corpus = tm_map(train_corpus, content_transformer(removePunctuation)) 
train_corpus = tm_map(train_corpus, content_transformer(stripWhitespace)) 
train_corpus = tm_map(train_corpus, content_transformer(removeWords), stopwords("SMART"))
```

#### Create training DTM & dense matrix: Turning this list into a document-term matrix. After that, we remove the sparce terms and include those terms which have a sparce factor of less than 97.5%
```{r}
DTM_train = DocumentTermMatrix(train_corpus)
DTM_train = removeSparseTerms(DTM_train, 0.975)
```

#### Creating the Testing Corpus. Just like the training corpus, the sys.glob function here is a function to do wildcard expansion on file paths
```{r}
author_dirs = Sys.glob('./ReutersC50/C50test/*')
file_list = NULL
test_labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first=22)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  test_labels = append(test_labels, rep(author_name, length(files_to_add)))
}
```

#### We perform Named conversion & cleanup of the file. The lapply function here returns a list of the same length as file_list, each element of which is the result of applying readerPlain to the corresponding element of file_list
```{r}
all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
```

#### Then, we initialize Training Corpus
```{r}
test_corpus = Corpus(VectorSource(all_docs))
names(test_corpus) = file_list
```

#### Tokenization of training Corpus: Now, in order to tokenize the training corpus, we follow the followin steps: First we convert the content of train_corpus to lowercase. Then, we remove numbers and punctuation. Next, we strip the white spaces
```{r}
test_corpus = tm_map(test_corpus, content_transformer(tolower)) 
test_corpus = tm_map(test_corpus, content_transformer(removeNumbers)) 
test_corpus = tm_map(test_corpus, content_transformer(removePunctuation)) 
test_corpus = tm_map(test_corpus, content_transformer(stripWhitespace)) 
test_corpus = tm_map(test_corpus, content_transformer(removeWords), stopwords("SMART"))
```

#### As we need a dictionary of terms from the training corpus in order to extract terms from the test corpus, we create a Dictionary 
```{r}
reuters_dict = NULL
reuters_dict = dimnames(DTM_train)[[2]]
```

#### Then, we create the testing document term matrix using dictionary words only
```{r}
DTM_test = DocumentTermMatrix(test_corpus, list(dictionary=reuters_dict))
DTM_test = removeSparseTerms(DTM_test, 0.975)
```

#### In order for it to work in classifier models, we convert DTMs into Data Frames 
```{r}
DTM_train_df = as.data.frame(inspect(DTM_train))
DTM_test_df = as.data.frame(inspect(DTM_test))
```

#### Random Forest Model
#### RandomForest requires the same variables in training and test sets. Therefore, we need to add empty columns in the test data set for words that appear in the training data, but not in the test data
```{r}
DTM_test = as.matrix(DTM_test)
DTM_train = as.matrix(DTM_train)

xx <- data.frame(DTM_test[,intersect(colnames(DTM_test), colnames(DTM_train))])
yy <- read.table(textConnection(""), col.names = colnames(DTM_train), colClasses = "integer")
library(plyr)
DTM_test_clean = rbind.fill(xx, yy)
DTM_test_df = as.data.frame(DTM_test_clean)

model_RF = randomForest(x=DTM_train_df, y=as.factor(train_labels), mtry=3, ntree=200)
pred_RF = predict(model_RF, data=DTM_test_clean)
table_RF = as.data.frame(table(pred_RF,test_labels))
plot = ggplot(table_RF)
plot + geom_tile(aes(x=test_labels, y=pred_RF, fill=Freq)) + 
  scale_x_discrete(name="Actual Class") + 
  scale_y_discrete(name="Predicted Class") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

conf_RF = confusionMatrix(table(pred_RF,test_labels))
conf_RF$overall
conf_RF_df = as.data.frame(conf_RF$byClass)
conf_RF_df[order(-conf_RF_df$Sensitivity),1:2]
```

#### Naive Bayes Model
```{r}
model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=1)

pred_NB = predict(model_NB, DTM_test_df)
table_NB = as.data.frame(table(pred_NB,test_labels))
plot = ggplot(table_NB)
plot + geom_tile(aes(x=test_labels, y=pred_NB, fill=Freq)) + 
  scale_x_discrete(name="Actual Class") + 
  scale_y_discrete(name="Predicted Class") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

conf_NB = confusionMatrix(table(pred_NB,test_labels))
conf_NB_df = as.data.frame(conf_NB$byClass)
conf_NB_df[order(-conf_NB_df$Sensitivity),1:2]
```

#### After running Naive Bayes and Random Forest models, we conclude that Random Forest, with an accuracy of 69.4% is better than Naive Bayes which has an accuracy of 18%. After looking at the confusion matrix, we conclude that the authors whose articles seem difficult from one another are: BradDorfman, EdnaFernandes, JaneMacartney, JonathanBirt, KeithWeir, KevinDrawbaugh, KirstinRidley, KirstinRidley, MureDickie, ScottHillis, WilliamKazer

###Question3: Association rule mining

####Importing arules library as it has a big ecosystem of packages built around it
```{r}
library(arules)
```

##### Read in the groceries file from users
```{r}
groceries1=read.transactions("C:/Users/Sadavath/Desktop/STA380-master/data/groceries.txt", format ="basket", sep = ",",
                             rm.duplicates = TRUE)
```

#### Now, we cast the groceries1 variable as a special arules "transactions" class
```{r}
playtrans <- as(groceries1, "transactions")
```

#### Now run the 'Apriori' algorithm. 
#### Look at rules with support > .01 & confidence >.5 & length (# artists) <= 4
```{r}
musicrules <- apriori(playtrans, 
                      parameter=list(support=.01, confidence=.5, maxlen=5))
```

#### Now, we look at the output
```{r}
inspect(musicrules)
```

#### Next, we see which Item-Sets are most likely to occur. We should remember that Higher Lift means higher statistical dependance. We chose 3 because this is the highest value of lift that shows us any subsets
```{r}
inspect(subset(musicrules, subset=lift > 3))
```

#### Let's see that subset where another product occurs at least 58% of the time along with certain products. I chose 58% as this a very strong confidence within this data beaucause a 59% confidence returns no subsets
```{r}
inspect(subset(musicrules, subset=confidence > 0.58))
```

#### Finally, we choose the subset that has the highest values for support and confidence
```{r}
inspect(subset(musicrules, subset=support > .012 & confidence > 0.58))
```

#### Based on the result, we infer that: (a) citrus fruit, root vegetables are bought together with 'other vegetables' (b) root vegetables, tropical fruit is bought together with 'other vegetables' (c) Curd, yogurt are bought along with whole milk (d) citrus fruit, root vegetables are bought along with other vegetables (e) root vegetables, tropical fruit are bought along with other vegetables

#### These item sets make sense as someone who most of these items are often purchased together in the grocery store